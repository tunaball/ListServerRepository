<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> find file duplicates on very large volume
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:x-apps%40listserver.themacintoshguy.com?Subject=find%20file%20duplicates%20on%20very%20large%20volume&In-Reply-To=list-7538067%40mail.ninewire.com">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000850.html">
   <LINK REL="Next"  HREF="000852.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">

<!--GoogleAdsAutomaticSizeSTART-->
<p align=CENTER>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Automatic Size -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1785703837751368"
     data-ad-slot="4468313549"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
</p>
<!--GoogleAdsAutomaticSizeEND-->

   <H1>find file duplicates on very large volume</H1>
    <B>R. Welz</B> 
    <A HREF="mailto:x-apps%40listserver.themacintoshguy.com?Subject=find%20file%20duplicates%20on%20very%20large%20volume&In-Reply-To=list-7538067%40mail.ninewire.com"
       TITLE="find file duplicates on very large volume">r_welz at gmx.de
       </A><BR>
    <I>Wed Jul 16 12:35:32 PDT 2003</I>
    <P><UL>
        <LI>Previous message: <A HREF="000850.html">G5 RAM
</A></li>
        <LI>Next message: <A HREF="000852.html">[X-Apps] find file duplicates on very large volume
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#851">[ date ]</a>
              <a href="thread.html#851">[ thread ]</a>
              <a href="subject.html#851">[ subject ]</a>
              <a href="author.html#851">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hello.
During my life as a macintosh user I collected many CDROMS (about 300
pieces). Now I got the Idea to copy all that on a (really) big HD
otherwise when I search for a file I have to crawl from cellar to the
roof.

My question is: When I have the HD with all the CDR on ot is there a
program which can handle and find duplicates? I mean not only duplicat
names but duplicate content (in text files for example). And with that
amount of content. And in reasonable time. Would SpringCleaning do the
job? How loNg would it take?

I have a G4 866 and would eventually buy 2x250 GB HD FireWire800.

Thank you for help.
Robert

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000850.html">G5 RAM
</A></li>
	<LI>Next message: <A HREF="000852.html">[X-Apps] find file duplicates on very large volume
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#851">[ date ]</a>
              <a href="thread.html#851">[ thread ]</a>
              <a href="subject.html#851">[ subject ]</a>
              <a href="author.html#851">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="../../../mailman/listinfo/x-apps.html">More information about the X-Apps
mailing list</a><br>
<hr />
<!--GoogleAdsAutomaticSizeSTART-->
<p align=CENTER>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Automatic Size -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1785703837751368"
     data-ad-slot="4468313549"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
</p>
<!--GoogleAdsAutomaticSizeEND-->

</body></html>

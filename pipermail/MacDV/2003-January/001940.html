<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [MacDV] Re: The Sony Canon debate
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:macdv%40listserver.themacintoshguy.com?Subject=%5BMacDV%5D%20Re%3A%20The%20Sony%20Canon%20debate&In-Reply-To=list-4652135%40mail.ninewire.com">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001939.html">
   <LINK REL="Next"  HREF="001941.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">

<!--GoogleAdsAutomaticSizeSTART-->
<p align=CENTER>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Automatic Size -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1785703837751368"
     data-ad-slot="4468313549"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
</p>
<!--GoogleAdsAutomaticSizeEND-->

   <H1>[MacDV] Re: The Sony Canon debate</H1>
    <B>Louis Demers</B> 
    <A HREF="mailto:macdv%40listserver.themacintoshguy.com?Subject=%5BMacDV%5D%20Re%3A%20The%20Sony%20Canon%20debate&In-Reply-To=list-4652135%40mail.ninewire.com"
       TITLE="[MacDV] Re: The Sony Canon debate">LouisDemers at mac.com
       </A><BR>
    <I>Wed Jan 29 19:22:58 PST 2003</I>
    <P><UL>
        <LI>Previous message: <A HREF="001939.html">[MacDV] Re: Okay I see -- iMovie 3 download
</A></li>
        <LI>Next message: <A HREF="001941.html">[MacDV] Re: Okay I see -- iMovie 3 download
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1940">[ date ]</a>
              <a href="thread.html#1940">[ thread ]</a>
              <a href="subject.html#1940">[ subject ]</a>
              <a href="author.html#1940">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>At 9:30 PM -0500 1/29/03, James Asherman wrote:
&gt;<i>Steven Rogers wrote:
</I>&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>On Wednesday, January 29, 2003, at 08:04 PM, Thubten Kunga wrote:
</I>&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>SteadyShot is better optical and Super SteadyShot is best optical.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>I tried to verify that somewhere on the web, but couldn't find it. 
</I>&gt;&gt;<i>Super SteadyShot is an optical technique. I couldn't find any 
</I>&gt;&gt;<i>documentation of what plain SteadyShot is.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>SR
</I>&gt;<i>
</I>&gt;<i><A HREF="http://www.digitalvideoforless.com/steadyshot.htm">http://www.digitalvideoforless.com/steadyshot.htm</A>
</I>&gt;<i>Jim
</I>


Ok, not to fuel a debate but this reference is similar to others I 
have seen.  I'm no video professional and I'm not looking for a 
fight. I'll let it go with one last description of how I understand 
all of this works from the perspective of an physics engineer who 
worked in real-time image processing, IR guided weapons...

I suspect our disagreement comes from our definition of optical stabilization.
So here is how I use those terms.


1) Pure Electronic Image Stabilization.

In this scheme sequential images are numerically/electronically 
compared. The last image is shifted through by various amounts in 
both directions until the difference is minimized. This is the image 
position that is recorded.  In high end implementation, the images 
can even be resampled and sub-pixel shifts can be evaluated. 
Obviously this require a lot of computing power but gives astonishing 
results and very high dynamic response for very high vibration 
situations. There are no mechanical moving parts which permits the 
high dynamic response. Because of the amount  of  computing power 
required, this is mostly for military  applications. The process of 
matching images is called image registration. This process requires 
the image sensor to be elarger than the final image size or black 
bands will appear on the side.


2) Hybrid Image Stabilization.

In this scheme, instead of comparing sequential images to measure the 
jitter, inertial sensors measure the acceleration vertically and 
horizontally. The acceleration are electronically integrated twice to 
compute the orientation change. The recent advent of silicon 
acceleration sensors permit very cheap and efficient motion sensing. 
Once the motion has been estimated, the image is shifted by the 
measured amount and recorded. This is the most affordable solution 
because it still use no mechanical parts and the use of sensors 
greatly reduce the amount of computing power that needs to be packed 
into the camera. However the sensors are not perfect and the measured 
motion is less accurate than method number 1. This also require an 
image sensor with more pixels than the final captured image to avoid 
black bands.


3) Mechanical or Gyroscopic Image Stabilization

Here, the entire camera/lens is mounted onto an inertial platform 
stabilized by gyroscopes, springs and dampers. Typically this setup 
can also be used to steer the camera and is found in systems from 
Flir, Wescam, Sonoma Design... You find these stabilization systems 
under Helicopters, Unmanned Aerial Vehicles, and even mounted on some 
rails next to Olympic tracks to follow runners. Hugely expansive, but 
very high performance and provides a steering of the camera also.

4) Optical Image Stabilization

Here, the camera uses a lens with a moveable optical group or prism . 
The group/prism can be shifted to counteract the pointing jitter. 
Typically, sensors (like in method 2) measure the jitter and instead 
of electronically shifting the image, the optical group is physically 
shifted to bring back the image on the same position on the sensor. 
Because of the requirement to physically move the optical group, the 
dynamic response is limited to lower frequency movements and very 
high frequency vibrations are not well cancelled. However the image 
can be shifted by minute amounts (fractions of a pixel) before 
capture by the sensor and this will generate better image capture. 
Physically moving elements also consumes more power and is harder on 
the batteries. This setup doesn't require image sensors to be larger 
than the final image size.

<A HREF="http://www.canondv.com/gl2/f_image_stabilization.html">http://www.canondv.com/gl2/f_image_stabilization.html</A>


My understanding is that all consumer and prosumer camcorders that 
announce stabilization use the method number 2 because it is cheaper 
and gives good enough results. I only know of the Canon GL1 or GL2 
class cameras that use method 4.


But then again what do I know ...


cheers.


PS: the link <A HREF="http://www.digitalvideoforless.com/steadyshot.htm">http://www.digitalvideoforless.com/steadyshot.htm</A> works for me.

-- 

Louis Demers ing.
<A HREF="../../../mailman/listinfo/macdv.html">Louis.Demers at videotron.ca</A>
<A HREF="../../../mailman/listinfo/macdv.html">LouisDemers at mac.com</A>

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001939.html">[MacDV] Re: Okay I see -- iMovie 3 download
</A></li>
	<LI>Next message: <A HREF="001941.html">[MacDV] Re: Okay I see -- iMovie 3 download
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1940">[ date ]</a>
              <a href="thread.html#1940">[ thread ]</a>
              <a href="subject.html#1940">[ subject ]</a>
              <a href="author.html#1940">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="../../../mailman/listinfo/macdv.html">More information about the MacDV
mailing list</a><br>
<hr />
<!--GoogleAdsAutomaticSizeSTART-->
<p align=CENTER>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Automatic Size -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1785703837751368"
     data-ad-slot="4468313549"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
</p>
<!--GoogleAdsAutomaticSizeEND-->

</body></html>
